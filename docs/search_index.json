[["index.html", "Reticular Action Model (RAM) Notation Notes Chapter 1 Description", " Reticular Action Model (RAM) Notation Notes Ivan Jacob Agaloos Pesigan 2021-01-23 Chapter 1 Description This is a collection of my notes on the Reticular Action Model (RAM) notation that accompanies the ramR package (Pesigan 2021) in the R statistical environment (R Core Team 2020). You can install the released version of ramR from GitHub with: remotes::install_github(&quot;jeksterslab/ramR&quot;) These notes are based on the following resources: Boker and McArdle (2005) McArdle and McDonald (1984) McArdle (2005) See GitHub Pages for the html deployment. "],["ram-matrix-notation.html", "Chapter 2 Reticular Action Model (RAM) Matrix Notation 2.1 Full Model 2.2 Observed/Manifest/Given Variables vs. Unobserved/Latent/Hidden Variables", " Chapter 2 Reticular Action Model (RAM) Matrix Notation 2.1 Full Model Definition 2.1 \\[\\begin{equation} \\mathbf{v} = \\mathbf{A} \\mathbf{v} + \\mathbf{u} \\end{equation}\\] where \\(\\mathbf{v}\\) and \\(\\mathbf{u}\\) are \\(t \\times 1\\) vectors of random variables \\(\\mathbf{A}\\) is a \\(t \\times t\\) matrix of directed or asymmetric relationship from column variable \\(v_j\\) to row variable \\(v_i\\) \\(\\mathbf{A}\\) represent the regression of each of the \\(t\\) variables \\(\\mathbf{v}\\) on the other \\(t - 1\\) variables diagonal \\(a_{i,i}\\) is zero \\(u_i\\) represent the residual of \\(v_i\\) if all regression coefficients on other variables are zero, then the variable \\(v_i\\) is considered the same as its own residual \\(u_i\\) Definition 2.2 \\[\\begin{equation} \\mathbf{S} = \\mathbb{E} \\left\\{ \\mathbf{u} \\mathbf{u}^{\\prime} \\right\\} , \\end{equation}\\] where \\(\\mathbf{S}\\) is a \\(t \\times t\\) matrix of undirected or symmetric relationship the notation \\(\\boldsymbol{\\Omega}\\) is used in other sources for \\(\\mathbf{S}\\) \\(\\mathbb{E}\\) is the expectation operator Definition 2.3 \\[\\begin{equation} \\mathbf{C} = \\mathbb{E} \\left\\{ \\mathbf{v} \\mathbf{v}^{\\prime} \\right\\} , \\end{equation}\\] where \\(\\mathbf{C}\\) is a \\(t \\times t\\) variance-covariance matrix the notation \\(\\boldsymbol{\\Sigma}\\) is used in other sources for \\(\\mathbf{C}\\) Definition 2.4 \\[\\begin{equation*} \\mathbf{v} = \\mathbf{A} \\mathbf{v} + \\mathbf{u} \\end{equation*}\\] can be rewritten as \\[\\begin{equation} \\begin{split} \\mathbf{v} - \\mathbf{A} \\mathbf{v} &amp;= \\mathbf{u} \\\\ \\mathbf{u} &amp;= \\mathbf{v} - \\mathbf{A} \\mathbf{v} \\\\ \\mathbf{u} &amp;= \\left( \\mathbf{I} - \\mathbf{A} \\right) \\mathbf{v} \\end{split} \\end{equation}\\] assuming that \\(\\left( \\mathbf{I} - \\mathbf{A} \\right)\\) is non-singular, \\[\\begin{equation} \\mathbf{E} = \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\end{equation}\\] then \\[\\begin{equation} \\begin{split} \\mathbf{v} &amp;= \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{u} \\\\ &amp;= \\mathbf{E} \\mathbf{u} . \\end{split} \\end{equation}\\] Using the definitions above, \\(\\mathbf{S}\\) and \\(\\mathbf{C}\\) are given by \\[\\begin{equation} \\begin{split} \\mathbf{S} &amp;= \\left( \\mathbf{I} - \\mathbf{A} \\right) \\mathbf{C} \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\\\ &amp;= \\mathbf{E}^{-1} \\mathbf{C} \\left( \\mathbf{E}^{-1} \\right)^{\\mathsf{T}} \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbf{C} &amp;= \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{S} \\left[ \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\right]^{\\mathsf{T}} \\\\ &amp;= \\mathbf{E} \\mathbf{S} \\mathbf{E}^{\\mathsf{T}} \\end{split} \\end{equation}\\] 2.2 Observed/Manifest/Given Variables vs. Unobserved/Latent/Hidden Variables Definition 2.5 \\[\\begin{equation} \\mathbf{v} = \\begin{bmatrix} \\mathbf{g}_{p \\times 1} \\\\ \\mathbf{h}_{q \\times 1} \\\\ \\end{bmatrix} \\end{equation}\\] \\[\\begin{equation} t = p + q \\end{equation}\\] \\(\\mathbf{g}\\) may be considered observed, manifest or given variables \\(\\mathbf{h}\\) may be considered unobserved, latent, or hidden variables Definition 2.6 \\[\\begin{equation} \\mathbf{F} = \\begin{bmatrix} \\mathbf{I}_{p \\times p} : \\mathbf{0}_{p \\times q} \\end{bmatrix} \\end{equation}\\] the \\(\\mathbf{F}\\) matrix acts as a filter to select the manifest variables out of the full set of manifest and latent variables \\[\\begin{equation} \\mathbf{g} = \\mathbf{F} \\mathbf{v} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbf{g} &amp;= \\mathbf{F} \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{u} \\\\ &amp;= \\mathbf{F} \\mathbf{E} \\mathbf{u} \\end{split} \\end{equation}\\] Definition 2.7 \\[\\begin{equation} \\mathbf{M} = \\mathbb{E} \\left\\{ \\mathbf{g} \\mathbf{g}^{\\mathsf{T}} \\right\\} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbf{M} &amp;= \\mathbf{F} \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{S} \\left[ \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\right]^{\\mathsf{T}} \\mathbf{F}^{\\mathsf{T}} \\\\ &amp;= \\mathbf{F} \\mathbf{E} \\mathbf{S} \\mathbf{E}^{\\mathsf{T}} \\mathbf{F}^{\\mathsf{T}} \\\\ &amp;= \\mathbf{F} \\mathbf{C} \\mathbf{F}^{\\mathsf{T}} \\end{split} \\end{equation}\\] when components of \\(\\mathbf{v}\\) are permuted, the columns of \\(\\mathbf{F}\\) can be correspondingly permuted the rows and columns of \\(\\mathbf{C}\\) that are filtered out by \\(\\mathbf{F}\\) contain useful information about the latent variable structure. The equations above completely define RAM. "],["ram-diagram.html", "Chapter 3 Reticular Action Model (RAM) Path Diagram", " Chapter 3 Reticular Action Model (RAM) Path Diagram Figure 3.1: Path Diagram Elements Figure 3.2: Two-Variable Regression Model Figure 3.3: \\(k\\)-Variable Regression Model Figure 3.4: Two-Factor Confirmatory Factor Analysis Model Figure 3.5: Two-Factor Confirmatory Factor Analysis Model with Mean Structure Figure 3.6: Path Model with Latent Variables "],["ram-t.html", "Chapter 4 Student’s \\(t\\)-test 4.1 Symbolic 4.2 Numerical Example 4.3 Equations to RAM 4.4 Equations to Expectations", " Chapter 4 Student’s \\(t\\)-test In this section, the Student’s \\(t\\)-test is presented as a structural equation model using the RAM notation. Let \\(y\\) be a continuous dependent variable, \\(x\\) be a dichotomous independent variable \\(\\left( x = \\{0, 1\\} \\right)\\), and \\(\\varepsilon\\) be the stochastic error term with mean 0 and constant variance of \\(\\sigma_{\\varepsilon}^{2}\\) across the values of \\(x\\). The associations of the variables are given by \\[\\begin{equation*} y = \\alpha + \\beta x + \\varepsilon \\end{equation*}\\] where \\(\\alpha\\) is the expected value of \\(y\\) when \\(x = 0\\) \\(\\beta\\) is the unit change in \\(y\\) for unit change in \\(x\\) \\(\\alpha + \\beta\\) is the expected value of \\(y\\) when \\(x = 1\\) Figure 4.1: Student’s \\(t\\)-test 4.1 Symbolic Let \\(\\left\\{ y, x, \\varepsilon \\right\\}\\) be the variables of interest. \\[\\begin{align*}\\mathbf{A} &amp;=\\left( \\begin{array}{ccc} 0 &amp; \\beta &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right)\\end{align*}\\] \\[\\begin{align*}\\mathbf{S} &amp;=\\left( \\begin{array}{ccc} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\sigma _{x} ^{2} &amp; 0 \\\\ 0 &amp; 0 &amp; \\sigma _{\\varepsilon } ^{2} \\end{array} \\right)\\end{align*}\\] \\[\\begin{align*}\\mathbf{C} &amp;=\\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{S} \\left[ \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\right]^{\\mathsf{T}} \\\\\\\\ &amp;=\\mathbf{E} \\mathbf{S} \\mathbf{E}^{\\mathsf{T}} \\\\\\\\ &amp;=\\left( \\begin{array}{ccc} 1 &amp; \\beta &amp; 1 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right)\\left( \\begin{array}{ccc} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\sigma _{x} ^{2} &amp; 0 \\\\ 0 &amp; 0 &amp; \\sigma _{\\varepsilon } ^{2} \\end{array} \\right)\\left( \\begin{array}{ccc} 1 &amp; \\beta &amp; 1 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right)^{\\mathsf{T}}\\\\ &amp;=\\left( \\begin{array}{ccc} \\sigma _{x} ^{2} \\beta ^{2} + \\sigma _{\\varepsilon } ^{2} &amp; \\beta \\sigma _{x} ^{2} &amp; \\sigma _{\\varepsilon } ^{2} \\\\ \\sigma _{x} ^{2} \\beta &amp; \\sigma _{x} ^{2} &amp; 0 \\\\ \\sigma _{\\varepsilon } ^{2} &amp; 0 &amp; \\sigma _{\\varepsilon } ^{2} \\end{array} \\right)\\end{align*}\\] \\[\\begin{align*}\\mathbf{F} &amp;=\\left( \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\end{array} \\right)\\end{align*}\\] \\[\\begin{align*}\\mathbf{M} &amp;=\\mathbf{F} \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{S} \\left[ \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\right]^{\\mathsf{T}} \\mathbf{F}^{\\mathsf{T}}\\\\ &amp;=\\mathbf{F} \\mathbf{E} \\mathbf{S} \\mathbf{E}^{\\mathsf{T}} \\mathbf{F}^{\\mathsf{T}} \\\\\\\\ &amp;=\\mathbf{F} \\mathbf{C} \\mathbf{F}^{\\mathsf{T}} \\\\\\\\ &amp;=\\left( \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\end{array} \\right)\\left( \\begin{array}{ccc} \\sigma _{x} ^{2} \\beta ^{2} + \\sigma _{\\varepsilon } ^{2} &amp; \\beta \\sigma _{x} ^{2} &amp; \\sigma _{\\varepsilon } ^{2} \\\\ \\sigma _{x} ^{2} \\beta &amp; \\sigma _{x} ^{2} &amp; 0 \\\\ \\sigma _{\\varepsilon } ^{2} &amp; 0 &amp; \\sigma _{\\varepsilon } ^{2} \\end{array} \\right)\\left( \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\end{array} \\right)^{\\mathsf{T}} \\\\\\\\ &amp;=\\left( \\begin{array}{cc} \\sigma _{x} ^{2} \\beta ^{2} + \\sigma _{\\varepsilon } ^{2} &amp; \\beta \\sigma _{x} ^{2} \\\\ \\sigma _{x} ^{2} \\beta &amp; \\sigma _{x} ^{2} \\end{array} \\right)\\end{align*}\\] \\[\\begin{align*}\\mathbf{v} &amp;=\\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{u}\\\\ &amp;=\\left[\\left( \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right)-\\left( \\begin{array}{ccc} 0 &amp; \\beta &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right)\\right]^{\\mathsf{-1}}\\left( \\begin{array}{c} \\alpha \\\\ \\mu _{x} \\\\ 0 \\end{array} \\right)\\\\ &amp;=\\left( \\begin{array}{c} \\alpha + \\beta \\mu _{x} \\\\ \\mu _{x} \\\\ 0 \\end{array} \\right)\\end{align*}\\] \\[\\begin{align*}\\mathbf{u} &amp;=\\left( \\mathbf{I} - \\mathbf{A} \\right) \\mathbf{v}\\\\ &amp;=\\left[\\left( \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right)-\\left( \\begin{array}{ccc} 0 &amp; \\beta &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right)\\right]\\left( \\begin{array}{c} \\alpha + \\beta \\mu _{x} \\\\ \\mu _{x} \\\\ 0 \\end{array} \\right)\\\\ &amp;=\\left( \\begin{array}{c} \\alpha \\\\ \\mu _{x} \\\\ 0 \\end{array} \\right)\\end{align*}\\] \\[\\begin{align*}\\mathbf{g} &amp;=\\mathbf{F} \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{u}\\\\ &amp;=\\left[\\left( \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right)-\\left( \\begin{array}{ccc} 0 &amp; \\beta &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right)\\right]^{-1}\\left( \\begin{array}{c} \\alpha \\\\ \\mu _{x} \\\\ 0 \\end{array} \\right)\\\\ &amp;=\\left( \\begin{array}{c} \\alpha + \\beta \\mu _{x} \\\\ \\mu _{x} \\end{array} \\right)\\end{align*}\\] 4.1.1 Using the ramR Package A ## y x e ## y &quot;0&quot; &quot;beta&quot; &quot;1&quot; ## x &quot;0&quot; &quot;0&quot; &quot;0&quot; ## e &quot;0&quot; &quot;0&quot; &quot;0&quot; S ## y x e ## y &quot;0&quot; &quot;0&quot; &quot;0&quot; ## x &quot;0&quot; &quot;sigma[x]^2&quot; &quot;0&quot; ## e &quot;0&quot; &quot;0&quot; &quot;sigma[varepsilon]^2&quot; u ## u ## y &quot;alpha&quot; ## x &quot;mu[x]&quot; ## e &quot;0&quot; filter ## y x e ## y 1 0 0 ## x 0 1 0 The covariance expectations can be symbolically derived using the ramR::C_sym() function. ramR::C_sym(A, S) ## {{sigma[x]^2*beta^2+sigma[varepsilon]^2, beta*sigma[x]^2, sigma[varepsilon]^2}, ## { sigma[x]^2*beta, sigma[x]^2, 0}, ## { sigma[varepsilon]^2, 0, sigma[varepsilon]^2}} \\[\\begin{equation*}\\mathbf{C} =\\left( \\begin{array}{ccc} \\sigma _{x} ^{2} \\beta ^{2} + \\sigma _{\\varepsilon } ^{2} &amp; \\beta \\sigma _{x} ^{2} &amp; \\sigma _{\\varepsilon } ^{2} \\\\ \\sigma _{x} ^{2} \\beta &amp; \\sigma _{x} ^{2} &amp; 0 \\\\ \\sigma _{\\varepsilon } ^{2} &amp; 0 &amp; \\sigma _{\\varepsilon } ^{2} \\end{array} \\right)\\end{equation*}\\] The covariance expectations for the observed variables can be symbolically derived using the ramR::M_sym() function. ramR::M_sym(A, S, filter) ## {{sigma[x]^2*beta^2+sigma[varepsilon]^2, beta*sigma[x]^2}, ## { sigma[x]^2*beta, sigma[x]^2}} \\[\\begin{equation*}\\mathbf{M} =\\left( \\begin{array}{cc} \\sigma _{x} ^{2} \\beta ^{2} + \\sigma _{\\varepsilon } ^{2} &amp; \\beta \\sigma _{x} ^{2} \\\\ \\sigma _{x} ^{2} \\beta &amp; \\sigma _{x} ^{2} \\end{array} \\right)\\end{equation*}\\] The mean expectations can be symbolically derived using the ramR::v_sym() function. ramR::v_sym(A, u) ## {{alpha+beta*mu[x]}, ## { mu[x]}, ## { 0}} \\[\\begin{equation*}\\mathbf{v} =\\left( \\begin{array}{c} \\alpha + \\beta \\mu _{x} \\\\ \\mu _{x} \\\\ 0 \\end{array} \\right)\\end{equation*}\\] The mean expectations for the observed variables can be symbolically derived using the ramR::g_sym() function. ramR::g_sym(A, u, filter) ## {{alpha+beta*mu[x]}, ## { mu[x]}} \\[\\begin{equation*}\\mathbf{g} =\\left( \\begin{array}{c} \\alpha + \\beta \\mu _{x} \\\\ \\mu _{x} \\end{array} \\right)\\end{equation*}\\] 4.2 Numerical Example Let df be a random sample with the following parameters Parameter \\(x = 0\\) \\(x = 1\\) Sample Size 500 500 \\(\\mu\\) 0 1 \\(\\sigma^2\\) 1 1 Parameter Description Estimate \\(\\alpha\\) Mean of \\(x = 0\\). 0 \\(\\beta\\) Mean of \\(x = 1\\) minus \\(x = 0\\). 1 head(df) ## y x ## 1 1.3709584 0 ## 2 -0.5646982 0 ## 3 0.3631284 0 ## 4 0.6328626 0 ## 5 0.4042683 0 ## 6 -0.1061245 0 summary(df) ## y x ## Min. :-2.9931 Min. :0.0 ## 1st Qu.:-0.2770 1st Qu.:0.0 ## Median : 0.4503 Median :0.5 ## Mean : 0.4742 Mean :0.5 ## 3rd Qu.: 1.2492 3rd Qu.:1.0 ## Max. : 4.4953 Max. :1.0 4.2.1 \\(t\\)-test t.test(y ~ x, data = df) ## ## Welch Two Sample t-test ## ## data: y by x ## t = -15.897, df = 994.36, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.1329278 -0.8839594 ## sample estimates: ## mean in group 0 mean in group 1 ## -0.03004622 0.97839737 4.2.2 Linear Regression summary(lm(y ~ x, data = df)) ## ## Call: ## lm(formula = y ~ x, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.3501 -0.6517 0.0086 0.6858 3.5169 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.03005 0.04486 -0.67 0.503 ## x 1.00844 0.06344 15.90 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.003 on 998 degrees of freedom ## Multiple R-squared: 0.2021, Adjusted R-squared: 0.2013 ## F-statistic: 252.7 on 1 and 998 DF, p-value: &lt; 2.2e-16 4.2.3 Structural Equation Modeling 4.2.3.1 lavaan (Rosseel 2012) model &lt;- &quot; y ~ x &quot; fit &lt;- lavaan::sem( model, data = df, meanstructure = TRUE, fixed.x = FALSE ) lavaan::summary(fit) ## lavaan 0.6-7 ended normally after 12 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of free parameters 5 ## ## Number of observations 1000 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x 1.008 0.063 15.913 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .y -0.030 0.045 -0.671 0.503 ## x 0.500 0.016 31.623 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 1.004 0.045 22.361 0.000 ## x 0.250 0.011 22.361 0.000 4.2.3.2 OpenMx (Boker et al. 2020) RAM matrices can be used to specify models in OpenMx. Note, however, that the u vector in the RAM notation is M in the OpenMx notation. mxData &lt;- OpenMx::mxData( observed = df, type = &quot;raw&quot; ) mxA &lt;- OpenMx::mxMatrix( type = &quot;Full&quot;, nrow = 3, ncol = 3, free = c( F, T, F, F, F, F, F, F, F ), values = c( 0, 0.20, 1, 0, 0, 0, 0, 0, 0 ), labels = c( NA, &quot;beta&quot;, NA, NA, NA, NA, NA, NA, NA ), byrow = TRUE, name = &quot;mxA&quot; ) mxS &lt;- OpenMx::mxMatrix( type = &quot;Symm&quot;, nrow = 3, ncol = 3, free = c( F, F, F, F, T, F, F, F, T ), values = c( 0, 0, 0, 0, 0.20, 0, 0, 0, 0.20 ), labels = c( NA, NA, NA, NA, &quot;sigma2x&quot;, NA, NA, NA, &quot;sigma2e&quot; ), byrow = TRUE, name = &quot;mxS&quot; ) mxM &lt;- OpenMx::mxMatrix( type = &quot;Full&quot;, nrow = 1, ncol = 3, free = c( T, T, F ), values = c( 0.20, 0.20, 0 ), labels = c( &quot;alpha&quot;, &quot;mux&quot;, NA ), byrow = TRUE, name = &quot;mxM&quot; ) mxF &lt;- OpenMx::mxMatrix( type = &quot;Full&quot;, nrow = 2, ncol = 3, free = FALSE, values = c( 1, 0, 0, 0, 1, 0 ), byrow = TRUE, name = &quot;mxF&quot; ) expRAM &lt;- OpenMx::mxExpectationRAM( A = &quot;mxA&quot;, S = &quot;mxS&quot;, F = &quot;mxF&quot;, M = &quot;mxM&quot;, dimnames = c( &quot;y&quot;, &quot;x&quot;, &quot;e&quot; ) ) objML &lt;- OpenMx::mxFitFunctionML() mxMod &lt;- OpenMx::mxModel( name = &quot;Model&quot;, data = mxData, matrices = list( mxA, mxS, mxF, mxM ), expectation = expRAM, fitfunction = objML ) fit &lt;- OpenMx::mxRun(mxMod) ## Running Model with 5 parameters summary(fit) ## Summary of Model ## ## free parameters: ## name matrix row col Estimate Std.Error A ## 1 beta mxA 1 2 1.00844356 0.06337369 ## 2 sigma2x mxS 2 2 0.25000000 0.01118034 ## 3 sigma2e mxS 3 3 1.00402596 0.04490152 ## 4 alpha mxM 1 y -0.03004621 0.04481202 ## 5 mux mxM 1 x 0.49999999 0.01581140 ## ## Model Statistics: ## | Parameters | Degrees of Freedom | Fit (-2lnL units) ## Model: 5 1995 4293.478 ## Saturated: 5 1995 NA ## Independence: 4 1996 NA ## Number of observations/statistics: 1000/2000 ## ## Information Criteria: ## | df Penalty | Parameters Penalty | Sample-Size Adjusted ## AIC: 303.4776 4303.478 4303.538 ## BIC: -9487.4941 4328.016 4312.136 ## CFI: NA ## TLI: 1 (also known as NNFI) ## RMSEA: 0 [95% CI (NA, NA)] ## Prob(RMSEA &lt;= 0.05): NA ## To get additional fit indices, see help(mxRefModels) ## timestamp: 2021-01-23 18:48:43 ## Wall clock time: 0.03867912 secs ## optimizer: SLSQP ## OpenMx version number: 2.18.1 ## Need help? See help(mxSummary) 4.2.4 Using the ramR Package A ## y x e ## y 0 1.008444 1 ## x 0 0.000000 0 ## e 0 0.000000 0 S ## y x e ## y 0 0.0000000 0.000000 ## x 0 0.2502503 0.000000 ## e 0 0.0000000 1.006038 u ## u ## y -0.03004622 ## x 0.50000000 ## e 0.00000000 filter ## y x e ## y 1 0 0 ## x 0 1 0 The covariance expectations can be numerically derived using the ramR::C_num() function. ramR::C_num(A, S) ## y x e ## y 1.2605321 0.2523633 1.006038 ## x 0.2523633 0.2502503 0.000000 ## e 1.0060380 0.0000000 1.006038 The covariance expectations for the observed variables can be numerically derived using the ramR::M_num() function. ramR::M_num(A, S, filter) ## y x ## y 1.2605321 0.2523633 ## x 0.2523633 0.2502503 The mean expectations can be numerically derived using the ramR::v_num() function. ramR::v_num(A, u) ## v ## y 0.4741756 ## x 0.5000000 ## e 0.0000000 The mean expectations for the observed variables can be numerically derived using the ramR::v_num() function. ramR::g_num(A, u, filter) ## g ## y 0.4741756 ## x 0.5000000 4.3 Equations to RAM The ramR package has a utility function to convert structural equations to RAM notation. The Student’s \\(t\\)-test can be expressed in the following equations eq &lt;- &quot; # VARIABLE1 OPERATION VARIABLE2 LABEL e by y 1 y on x beta e with e sigma[varepsilon]^2 x with x sigma[x]^2 y on 1 alpha x on 1 mu[x] &quot; Figure 4.2: Student’s \\(t\\)-test’s Structural Equations The error term is treated as a latent variable and defined with the operation by. Its value is constrained to \\(1\\). The regression of \\(y\\) on \\(x\\) is defined by operation on. It is labeled as beta. The variance of \\(x\\) and the error variance are defined using the operation with. These are labeled sigma[x]^2 and sigma[varepsilon]^2 respectively. The intercept and the mean of \\(x\\) are defined using the operation on 1. These are labeled alpha and mu[x] respectively. The ramR::eq2ram converts the equations to RAM notation. ramR::eq2ram(eq) ## $eq ## var1 op var2 label ## 1 e by y 1 ## 2 y on x beta ## 3 e with e sigma[varepsilon]^2 ## 4 x with x sigma[x]^2 ## 5 y on 1 alpha ## 6 x on 1 mu[x] ## ## $variables ## [1] &quot;y&quot; &quot;x&quot; &quot;e&quot; ## ## $A ## y x e ## y &quot;0&quot; &quot;beta&quot; &quot;1&quot; ## x &quot;0&quot; &quot;0&quot; &quot;0&quot; ## e &quot;0&quot; &quot;0&quot; &quot;0&quot; ## ## $S ## y x e ## y &quot;0&quot; &quot;0&quot; &quot;0&quot; ## x &quot;0&quot; &quot;sigma[x]^2&quot; &quot;0&quot; ## e &quot;0&quot; &quot;0&quot; &quot;sigma[varepsilon]^2&quot; ## ## $filter ## y x e ## y 1 0 0 ## x 0 1 0 ## ## $u ## u ## y &quot;alpha&quot; ## x &quot;mu[x]&quot; ## e &quot;0&quot; 4.4 Equations to Expectations The ramR package has a utility function to convert structural equations to expectations both symbolically and numerically. eq &lt;- &quot; # VARIABLE1 OPERATION VARIABLE2 LABEL e by y 1 y on x beta e with e sigma[varepsilon]^2 x with x sigma[x]^2 y on 1 alpha x on 1 mu[x] &quot; ramR::eq2exp_sym(eq) ## $variables ## [1] &quot;y&quot; &quot;x&quot; &quot;e&quot; ## ## $A ## {{ 0, beta, 1}, ## { 0, 0, 0}, ## { 0, 0, 0}} ## ## $S ## {{ 0, 0, 0}, ## { 0, sigma[x]^2, 0}, ## { 0, 0, sigma[varepsilon]^2}} ## ## $u ## {{alpha}, ## {mu[x]}, ## { 0}} ## ## $filter ## {{1, 0, 0}, ## {0, 1, 0}} ## ## $v ## {{alpha+beta*mu[x]}, ## { mu[x]}, ## { 0}} ## ## $g ## {{alpha+beta*mu[x]}, ## { mu[x]}} ## ## $C ## {{sigma[x]^2*beta^2+sigma[varepsilon]^2, beta*sigma[x]^2, sigma[varepsilon]^2}, ## { sigma[x]^2*beta, sigma[x]^2, 0}, ## { sigma[varepsilon]^2, 0, sigma[varepsilon]^2}} ## ## $M ## {{sigma[x]^2*beta^2+sigma[varepsilon]^2, beta*sigma[x]^2}, ## { sigma[x]^2*beta, sigma[x]^2}} eq &lt;- &quot; # VARIABLE1 OPERATION VARIABLE2 VALUE e by y 1.00 y on x 1.00 e with e 1.00 x with x 0.25 y on 1 0.00 x on 1 0.50 &quot; ramR::eq2exp_num(eq) ## $variables ## [1] &quot;y&quot; &quot;x&quot; &quot;e&quot; ## ## $A ## y x e ## y 0 1 1 ## x 0 0 0 ## e 0 0 0 ## ## $S ## y x e ## y 0 0.00 0 ## x 0 0.25 0 ## e 0 0.00 1 ## ## $u ## u ## y 0.0 ## x 0.5 ## e 0.0 ## ## $filter ## y x e ## y 1 0 0 ## x 0 1 0 ## ## $v ## v ## y 0.5 ## x 0.5 ## e 0.0 ## ## $g ## g ## y 0.5 ## x 0.5 ## ## $C ## y x e ## y 1.25 0.25 1 ## x 0.25 0.25 0 ## e 1.00 0.00 1 ## ## $M ## y x ## y 1.25 0.25 ## x 0.25 0.25 "],["references.html", "References", " References Boker, Steven M., and John J. McArdle. 2005. “Path Analysis and Path Diagrams.” In Encyclopedia of Statistics in Behavioral Science, edited by Brian S. Everitt and David C. Howell, 1529–31. Chichester, UK: John Wiley &amp; Sons, Ltd. https://doi.org/10.1002/0470013192.bsa471. Boker, Steven M., Michael C. Neale, Hermine H. Maes, Michael J. Wilde, Michael Spiegel, Timothy R. Brick, Ryne Estabrook, et al. 2020. OpenMx 2.18.1 User Guide. McArdle, John J. 2005. “The Development of the RAM Rules for Latent Variable Structural Equation Modeling.” In Contemporary Psychometrics: A Festschrift for Roderick P. McDonald, edited by Albert Maydeu-Olivares and John J. McArdle, 225–73. Multivariate Applications Book Series. Mahwah, NJ: Lawrence Erlbaum Associates. McArdle, John J., and Roderick P. McDonald. 1984. “Some Algebraic Properties of the Reticular Action Model for Moment Structures.” British Journal of Mathematical and Statistical Psychology 37 (2): 234–51. https://doi.org/10.1111/j.2044-8317.1984.tb00802.x. Pesigan, Ivan Jacob Agaloos. 2021. ramR: Reticular Action Model (RAM) Notation. https://github.com/jeksterslab/ramR. R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Rosseel, Yves. 2012. “lavaan: An R Package for Structural Equation Modeling.” Journal of Statistical Software 48 (2): 1–36. http://www.jstatsoft.org/v48/i02/. "]]
