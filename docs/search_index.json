[["index.html", "Reticular Action Model (RAM) Notation Chapter 1 Description", " Reticular Action Model (RAM) Notation Ivan Jacob Agaloos Pesigan 2021-01-10 Chapter 1 Description This is a collection of my personal notes on the Reticular Action Model (RAM) notation that accompanies the ramR package. You can install the released version of ramR from GitHub with: remotes::install_github(&quot;jeksterslab/ramR&quot;) These notes are based on the following resources: Boker and McArdle (2005) McArdle and McDonald (1984) McArdle (2005) See GitHub Pages for the html deployment. "],["ram-matrix-notation.html", "Chapter 2 Reticular Action Model (RAM) Matrix Notation 2.1 Model-Implied Matrices 2.2 Parameters", " Chapter 2 Reticular Action Model (RAM) Matrix Notation \\[\\begin{equation} \\mathbf{v} = \\mathbf{A} \\mathbf{v} + \\mathbf{u} \\end{equation}\\] where \\(\\mathbf{v}\\) is a \\(t \\times 1\\) vector of random variables \\(u_i\\) represent the residual of \\(v_i\\) \\(\\mathbf{A}\\) is a \\(t \\times t\\) matrix of directed or asymmetric relationship from column variable \\(v_j\\) to row variable \\(v_i\\) regression of each of the \\(t\\) variables on the other \\(t - 1\\) variables diagonal \\(a_{i,i}\\) is zero if all regression coefficients on other variables are zero, then the variable \\(v_i\\) is considered the same as its own residual \\(u_i\\) \\[\\begin{equation} \\boldsymbol{\\Omega} = \\mathbb{E} \\left( \\mathbf{u} \\mathbf{u}^{\\prime} \\right) \\end{equation}\\] where \\(\\boldsymbol{\\Omega}\\) is a \\(t \\times t\\) matrix of undirected or symmetric relationship \\[\\begin{equation} \\boldsymbol{\\Sigma} \\left( \\boldsymbol{\\theta} \\right) = \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\boldsymbol{\\Omega} \\left[ \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\right]^{\\mathsf{T}} \\end{equation}\\] \\(\\boldsymbol{\\Sigma} \\left( \\boldsymbol{\\theta} \\right)\\) is a \\(t \\times t\\) symmetric matrix of associations between \\(v_i\\) and \\(v_j\\) \\[\\begin{equation} \\mathbf{v}^{\\mathsf{T}} = \\left[ \\mathbf{m}, \\mathbf{l} \\right]^{\\mathsf{T}} \\end{equation}\\] where \\(\\mathbf{m}\\) are observed or manifest variables of \\(j\\) components \\(\\mathbf{l}\\) are observed or manifest variables of \\(k\\) components \\(t = j + k\\) \\[\\begin{equation} \\mathbf{F} = \\left[ \\mathbf{I}_{j} \\colon \\mathbf{O}_{j \\times k} \\right] \\end{equation}\\] the \\(\\mathbf{F}\\) matrix acts as a filter to select the manifest variables out of the full set of manifest and latent variables 2.1 Model-Implied Matrices The model-implied mean vector \\(\\boldsymbol{\\mu} \\left( \\boldsymbol{\\theta} \\right)\\) as a function of Reticular Action Model (RAM) matrices is given by \\[\\begin{equation} \\boldsymbol{\\mu} \\left( \\boldsymbol{\\theta} \\right) = \\mathbf{F} \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\mathbf{m} . \\end{equation}\\] The ramR::mutheta() function can be used to derive the model-implied mean vector. The model-implied variance-covariance matrix \\(\\boldsymbol{\\Sigma} \\left( \\boldsymbol{\\theta} \\right)\\) as a function of Reticular Action Model (RAM) matrices is given by \\[\\begin{equation} \\boldsymbol{\\Sigma} \\left( \\boldsymbol{\\theta} \\right) = \\mathbf{F} \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\boldsymbol{\\Omega} \\left[ \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\right]^{\\mathsf{T}} \\mathbf{F}^{\\mathsf{T}} . \\end{equation}\\] The ramR::Sigmatheta() function can be used to derive the model-implied variance-covariance matrix. 2.2 Parameters 2.2.1 Mean Structure \\[\\begin{equation} \\mathbf{m} = \\left[ \\mathbf{F} \\left( \\mathbf{I} - \\mathbf{A} \\right)^{-1} \\right]^{-1} \\boldsymbol{\\mu} \\left( \\boldsymbol{\\theta} \\right) \\end{equation}\\] The ramR::m() function can be used to derive the mean structure vector. 2.2.2 Covariance Structure \\[\\begin{equation} \\boldsymbol{\\Omega} = \\left( \\mathbf{I} - \\mathbf{A} \\right) \\boldsymbol{\\Sigma} \\left( \\boldsymbol{\\theta} \\right) \\left( \\mathbf{I} - \\mathbf{A} \\right)^{\\mathsf{T}} \\end{equation}\\] The ramR::Omega() function can be used to derive the symmetric matrix \\(\\boldsymbol{\\Omega}\\). TODO: Figure out how to isolate the A matrix "],["simple-regression.html", "Chapter 3 Simple Regression 3.1 Specification 1 - Includes Error Term as a Latent Variable 3.2 Specification 2 - Observed Variables", " Chapter 3 Simple Regression Let \\(v_1\\), \\(v_2\\), and \\(v_3\\) be random variables whose associations are given by the regression equation \\[\\begin{equation} \\begin{split} v_1 &amp;= m_1 + a_{1, 2} v_2 + v_3 \\\\ &amp;= -3.951208 + 1.269259 \\cdot v_2 + v_3 . \\end{split} \\end{equation}\\] \\(v_1\\) and \\(v_2\\) are observed variables and \\(v_3\\) is a stochastic error term which is normally distributed around zero with constant variance across values of \\(v_2\\) \\[\\begin{equation} v_3 \\sim \\mathcal{N} \\left( m_3 = 0, \\omega_{3, 3} = 47.659854 \\right) . \\end{equation}\\] \\(v_2\\) has a mean of \\(m_2 = 13.038328\\) and a variance of \\(\\omega_{2, 2} = 7.151261\\). 3.0.1 Expectations \\[\\begin{equation} \\begin{split} \\mathbb{E} \\left( v_3 \\right) &amp;= m_3 \\\\ &amp;= 0 \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbb{E} \\left( v_2 \\right) &amp;= m_2 \\\\ &amp;= 13.038328 \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbb{E} \\left( v_1 \\right) &amp;= \\mathbb{E} \\left( m_1 + a_{1, 2} v_2 + v_3 \\right) \\\\ &amp;= \\mathbb{E} \\left( m_1 \\right) + \\mathbb{E} \\left( a_{1, 2} v_2 \\right) + \\mathbb{E} \\left( v_3 \\right) \\\\ &amp;= m_1 + a_{1, 2} \\mathbb{E} \\left( v_2 \\right) + 0 \\\\ &amp;= m_1 + a_{1, 2} m_2 \\\\ &amp;= -3.951208 + 1.269259 \\times 13.038328 \\\\ &amp;= 12.5978072 \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbb{E} \\left( \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\right) &amp;= \\begin{bmatrix} m_1 + a_{1, 2} m_2 \\\\ m_2 \\\\ m_3 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 12.5978072 \\\\ 13.038328 \\\\ 0 \\end{bmatrix} \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathrm{Cov} \\left( v_3, v_3 \\right) &amp;= \\mathrm{Var} \\left( v_3 \\right) \\\\ &amp;= \\omega_{3, 3} \\\\ &amp;= 47.659854 \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathrm{Cov} \\left( v_1, v_3 \\right) &amp;= \\mathrm{Cov} \\left( a_{1, 2} v_2 + v_3, v_3 \\right) \\\\ &amp;= \\mathrm{Cov} \\left( a_{1, 2} v_2, v_3 \\right) + \\mathrm{Cov} \\left( v_3, v_3 \\right) \\\\ &amp;= a_{1, 2}^{2} \\mathrm{Cov} \\left( v_2, v_3 \\right) + \\mathrm{Var} \\left( v_3 \\right) \\\\ &amp;= a_{1, 2}^{2} \\cdot 0 + \\omega_{3, 3} \\\\ &amp;= 0 + \\omega_{3, 3} \\\\ &amp;= \\omega_{3, 3} \\\\ &amp;= 47.659854 \\end{split} \\end{equation}\\] \\[\\begin{equation} \\mathrm{Cov} \\left( v_2, v_3 \\right) = 0 \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathrm{Cov} \\left( v_1, v_1 \\right) &amp;= \\mathrm{Cov} \\left( a_{1, 2} v_2 + v_3, a_{1, 2} v_2 + v_3 \\right) \\\\ &amp;= \\mathrm{Cov} \\left( a_{1, 2} v_2, a_{1, 2} v_2 \\right) + \\mathrm{Cov} \\left( a_{1, 2} v_2, v_3 \\right) + \\mathrm{Cov} \\left( a_{1, 2} v_2, v_3 \\right) + \\mathrm{Cov} \\left( v_3, v_3 \\right) \\\\ &amp;= a_{1, 2}^{2} \\mathrm{Cov} \\left( v_2, v_2 \\right) + a_{1, 2} \\mathrm{Cov} \\left( v_2, v_3 \\right) + a_{1, 2} \\mathrm{Cov} \\left( v_2, v_3 \\right) + \\mathrm{Var} \\left( v_3 \\right) \\\\ &amp;= a_{1, 2}^{2} \\mathrm{Var} \\left( v_2 \\right) + a_{1, 2} \\cdot 0 + a_{1, 2} \\cdot 0 + \\omega_{3, 3} \\\\ &amp;= a_{1, 2}^{2} \\mathrm{Var} \\left( v_2 \\right) + 0 + 0 + \\omega_{3, 3} \\\\ &amp;= a_{1, 2}^{2} \\omega_{2, 2} + \\omega_{3, 3} \\\\ &amp;= 1.269259^{2} \\times 7.151261 + 47.659854 \\\\ &amp;= 59.1806671 \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathrm{Cov} \\left( v_2, v_1 \\right) &amp;= \\mathrm{Cov} \\left( v_2, a_{1, 2} v_2 + v_3 \\right) \\\\ &amp;= \\mathrm{Cov} \\left( v_2, a_{1, 2} v_2 \\right) + \\mathrm{Cov} \\left( v_2, v_3 \\right) \\\\ &amp;= a_{1, 2} \\mathrm{Cov} \\left( v_2, v_2 \\right) + 0 \\\\ &amp;= a_{1, 2} \\mathrm{Var} \\left( v_2 \\right) \\\\ &amp;= a_{1, 2} \\omega_{2, 2} \\\\ &amp;= 1.269259 \\times 7.151261 \\\\ &amp;= 9.0768024 \\\\ \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathrm{Cov} \\left( v_2, v_2 \\right) &amp;= \\mathrm{Var} \\left( v_2 \\right) \\\\ &amp;= \\omega_{2, 2} \\\\ &amp;= 7.151261 \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathrm{Cov} \\left( \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\right) &amp;= \\begin{bmatrix} a_{1, 2}^{2} \\omega_{2, 2} + \\omega_{3, 3} &amp; a_{1, 2} \\omega_{2, 2} &amp; \\omega_{3, 3} \\\\ a_{1, 2} \\omega_{2, 2} &amp; \\omega_{2, 2} &amp; 0 \\\\ \\omega_{3, 3} &amp; 0 &amp; \\omega_{3, 3} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 59.1806671 &amp; 9.0768024 &amp; 47.659854 \\\\ 9.0768024 &amp; 7.151261 &amp; 0 \\\\ 47.659854 &amp; 0 &amp; 47.659854 \\end{bmatrix} \\end{split} \\end{equation}\\] Below are two ways of specifying this model. The first specification includes the error term \\(v_3\\) as a latent variable. The second specification only includes the observed variables. 3.1 Specification 1 - Includes Error Term as a Latent Variable 3.1.1 Matrix Notation \\[\\begin{equation} \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbf{A} &amp;= \\begin{bmatrix} 0 &amp; a_{1, 2} &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 0 &amp; 1.269259 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{bmatrix} \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\boldsymbol{\\Omega} &amp;= \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\omega_{2, 2} &amp; 0 \\\\ 0 &amp; 0 &amp; \\omega_{3, 3} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 7.151261 &amp; 0 \\\\ 0 &amp; 0 &amp; 47.659854 \\end{bmatrix} \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbf{m} &amp;= \\begin{bmatrix} m_1 \\\\ m_2 \\\\ m_3 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} -3.951208 \\\\ 13.038328 \\\\ 0 \\end{bmatrix} \\end{split} \\end{equation}\\] To filter the observed variables, use the following filter matrix \\[\\begin{equation} \\mathbf{F} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\end{bmatrix} . \\end{equation}\\] To include all variables, use the following filter matrix \\[\\begin{equation} \\mathbf{F} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} . \\end{equation}\\] Figure 3.1: The Simple Linear Regression Model (with \\(v_3\\)) 3.1.1.1 Using the ramR Package knitr::kable( ramR::mutheta( m, A = A, filter = filter ), col.names = &quot;$\\\\boldsymbol{\\\\mu}$&quot;, caption = &quot;$\\\\boldsymbol{\\\\mu} \\\\left( \\\\boldsymbol{\\\\theta} \\\\right)$&quot;, escape = FALSE ) Table 3.1: \\(\\boldsymbol{\\mu} \\left( \\boldsymbol{\\theta} \\right)\\) \\(\\boldsymbol{\\mu}\\) \\(v_1\\) 12.59781 \\(v_2\\) 13.03833 \\(v_3\\) 0.00000 knitr::kable( ramR::Sigmatheta( A = A, Omega = Omega, filter = filter ), caption = &quot;$\\\\boldsymbol{\\\\Sigma} \\\\left( \\\\boldsymbol{\\\\theta} \\\\right)$&quot;, escape = FALSE ) Table 3.2: \\(\\boldsymbol{\\Sigma} \\left( \\boldsymbol{\\theta} \\right)\\) \\(v_1\\) \\(v_2\\) \\(v_3\\) \\(v_1\\) 59.180667 9.076802 47.65985 \\(v_2\\) 9.076802 7.151261 0.00000 \\(v_3\\) 47.659854 0.000000 47.65985 3.2 Specification 2 - Observed Variables 3.2.1 Matrix Notation \\[\\begin{equation} \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbf{A} &amp;= \\begin{bmatrix} 0 &amp; a_{1, 2} \\\\ 0 &amp; 0 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 0 &amp; 1.269259 \\\\ 0 &amp; 0 \\end{bmatrix} \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\boldsymbol{\\Omega} &amp;= \\begin{bmatrix} \\omega_{1, 1} &amp; 0 \\\\ 0 &amp; \\omega_{2, 2} \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} 47.659854 &amp; 0 \\\\ 0 &amp; 7.151261 \\end{bmatrix} \\end{split} \\end{equation}\\] \\[\\begin{equation} \\begin{split} \\mathbf{m} &amp;= \\begin{bmatrix} m_1 \\\\ m_2 \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} -3.951208 \\\\ 13.038328 \\end{bmatrix} \\end{split} \\end{equation}\\] \\[\\begin{equation} \\mathbf{F} = \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\end{equation}\\] Figure 3.2: The Simple Linear Regression Model (without \\(v_3\\)) 3.2.1.1 Using the ram() Package knitr::kable( ramR::mutheta( m, A = A, filter = filter ), col.names = &quot;$\\\\boldsymbol{\\\\mu}$&quot;, caption = &quot;$\\\\boldsymbol{\\\\mu} \\\\left( \\\\boldsymbol{\\\\theta} \\\\right)$&quot;, escape = FALSE ) Table 3.3: \\(\\boldsymbol{\\mu} \\left( \\boldsymbol{\\theta} \\right)\\) \\(\\boldsymbol{\\mu}\\) \\(v_1\\) 12.59781 \\(v_2\\) 13.03833 knitr::kable( ramR::Sigmatheta( A = A, Omega = Omega, filter = filter ), caption = &quot;$\\\\boldsymbol{\\\\Sigma} \\\\left( \\\\boldsymbol{\\\\theta} \\\\right)$&quot;, escape = FALSE ) Table 3.4: \\(\\boldsymbol{\\Sigma} \\left( \\boldsymbol{\\theta} \\right)\\) \\(v_1\\) \\(v_2\\) \\(v_1\\) 59.180667 9.076802 \\(v_2\\) 9.076802 7.151261 "],["references.html", "References", " References Boker, Steven M., and John J. McArdle. 2005. “Path Analysis and Path Diagrams.” In Encyclopedia of Statistics in Behavioral Science, edited by Brian S. Everitt and David C. Howell, 1529–31. Chichester, UK: John Wiley &amp; Sons, Ltd. https://doi.org/10.1002/0470013192.bsa471. McArdle, John J. 2005. “The Development of the RAM Rules for Latent Variable Structural Equation Modeling.” In Contemporary Psychometrics: A Festschrift for Roderick P. McDonald, edited by Albert Maydeu-Olivares and John J. McArdle, 225–73. Multivariate Applications Book Series. Mahwah, NJ: Lawrence Erlbaum Associates. McArdle, John J., and Roderick P. McDonald. 1984. “Some Algebraic Properties of the Reticular Action Model for Moment Structures.” British Journal of Mathematical and Statistical Psychology 37 (2): 234–51. https://doi.org/10.1111/j.2044-8317.1984.tb00802.x. "]]
